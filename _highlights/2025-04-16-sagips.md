---
title: SAGIPS highlight
layout: highlight
author: Daniel Lersch
summary: This work introduces a Scalable Asynchronous Generative Inverse Problem Solver (SAGIPS) on high-performance computing systems. The resulting workflow utilizes an asynchronous ring-allreduce algorithm to transfer the gradients of a GAN generator network across multiple GPUs. Experiments with a scientific proxy application demonstrate that SAGIPS shows near linear weak scaling. The observed convergence quality is comparable to traditional methods. The approach presented here allows leveraging Generative Adverserial Network across multiple GPUs, promising advancements in solving complex inverse problems at scale.
#image: /assets/img/sagips_linear_scaling.png
---

### Background

The goal of the QuantOm collaboration is to analyze nuclear physics scattering data in order to determine the underlying parton distributions. This represents an inverse problem, and tackling such problems is crucial in both contemporary research and various industrial contexts. Meanwhile, deep learning methods have gained traction by successfully addressing complex challenges. Consequently, it makes sense to develop a general-purpose inverse problem solver powered by deep learning techniques.

### The Science

The core of the proposed inverse problem solver is a Generative Adversarial Network (GAN). The generator proposes candidate parton density functions, which are then fed into a simulation pipeline that converts these predictions into synthetic nuclear scattering events. The discriminator compares these generated events against real experimental data and guides the generator’s learning. Training continues until the discriminator can no longer distinguish synthetic events from actual measurements. At that point, the generator produces parton densities that accurately capture the behavior of quarks and gluons.

The simulation pipeline itself consists of theoretical calculations that translate the generator’s density predictions into nuclear scattering cross sections. A subsequent sampler produces individual scattering events based on these cross sections, and a final module applies experimental effects (e.g. resolution and background contributions) to mirror the conditions under which the real data were collected.

Two major challenges arise when designing this solver:
 - **Data Volume**: The sheer size of the datasets can exceed the memory capacity of a single GPU.
 - **Computational Load**: The multi-stage pipeline demands substantial processing power.

    - Data volume: The sheer size of the datasets can exceed the memory capacity of a single GPU.

    Computational load: The multi-stage pipeline demands substantial processing power which may delay the communication between the generator and discriminator. 

To overcome these hurdles, this work introduces an asynchronous ring–all–reduce algorithm that distributes the generator’s gradient updates across multiple GPUs. Extensive experiments with a toy proxy problem on the Polaris HPC system showed that this distributed training method follows weak linear scaling and is superior to the horovod distributed framework. 

This solver is designed to support alternative deep learning or machine learning approaches beyond GANs, offering users greater flexibility.

### Contact

Daniel Lersch (<dlersch@jlab.org>)

### Reference

[Springer Machine Learning: Science and Technology](https://iopscience.iop.org/article/10.1088/2632-2153/adc8fb)
